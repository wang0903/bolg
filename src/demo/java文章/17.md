---
icon: pen-to-square
date: 2026-02-03
category:
  - java
tag:
  - ClickHouse
  - Kafka
  - Canal
star: true
sticky: true #标记
---
# Kafka、ClickHouse、Canal组合

## 结构图

![img](https://camo.githubusercontent.com/b5647a485e3a57e01e8d438f16a36420fbd274ade69a3f95f7688b2f109910c6/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f32303139313130343130313733353934372e706e67)



## 连接ClickHouse

```sh
192.168.1.171:8123
用户名:default
密码:123456
```

使用工具：DBeaver   软件地址:https://dbeaver.io/

```sql
select * from `default`.system_operate_log_storage #查看日志表
```

## 目录结构

```sh
/opt/log-stack
├── docker-compose.yml
├── canal/
│   └── instance.properties
├── data/
│   ├── kafka/
│   ├── clickhouse/
│   └── canal/
```

## 给MySQL创建账号

```sql
-- 创建 Canal 用户
CREATE USER 'canal'@'%' IDENTIFIED BY 'canal123';
GRANT SELECT, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'canal'@'%';
FLUSH PRIVILEGES;
```

### 配置文件信息

```conf
[mysqld]
server-id=1
log-bin=mysql-bin
binlog_format=ROW
```

## 部署代码

### docker-compose.yml

```yaml
services:

  kafka:
    image: swr.cn-north-4.myhuaweicloud.com/ddn-k8s/docker.io/bitnami/kafka:4.0.0
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      - KAFKA_CFG_NODE_ID=1
      - KAFKA_CFG_PROCESS_ROLES=broker,controller
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@kafka:9093
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=PLAINTEXT
      - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=true
      - KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR=1
      - KAFKA_CFG_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1
      - KAFKA_CFG_TRANSACTION_STATE_LOG_MIN_ISR=1
    volumes:
      - ./data/kafka:/bitnami/kafka
    restart: always

  canal:
    image: swr.cn-north-4.myhuaweicloud.com/ddn-k8s/docker.io/canal/canal-server:v1.1.8
    container_name: canal
    depends_on:
      - kafka
    ports:
      - "11111:11111"
    volumes:
      - /opt/log-stack/canal/syslog/instance.properties:/home/admin/canal-server/conf/syslog/instance.properties
      - ./data/canal:/home/admin/canal-server/meta
    environment:
      - canal.instance.mysql.slaveId=555
      - TZ=Asia/Shanghai
    restart: always

  clickhouse:
    image: swr.cn-north-4.myhuaweicloud.com/ddn-k8s/docker.io/clickhouse/clickhouse-server:latest
    container_name: clickhouse
    ports:
      - "8123:8123"
      - "9000:9000"
      - "9004:9004"
    environment:
      - TZ=Asia/Shanghai
      - CLICKHOUSE_USER=default
      - CLICKHOUSE_PASSWORD=123456
      - CLICKHOUSE_DB=default
    volumes:
      - ./data/clickhouse:/var/lib/clickhouse
    ulimits:
      nofile:
        soft: 262144
        hard: 262144
    restart: always
```

## Canal配置文件(每个表一个Kafka topic)

### instance.properties(system_operate_log)

```properties

# instance文件名称
canal.instance.destination = syslog

# MySQL 主库地址
canal.instance.master.address=192.168.1.163:3308

# MySQL 账号（必须有 REPLICATION 权限）
canal.instance.dbUsername=canal
canal.instance.dbPassword=canal135246

# binlog 位置自动
canal.instance.master.journal.name=
canal.instance.master.position=

# ROW 模式（强烈推荐）
canal.instance.binlog.format=ROW
canal.instance.binlog.image=FULL

# 只监听日志 & 业务表（按你实际改）
canal.instance.filter.regex=test.*

# 输出到 Kafka
canal.mq.servers = kafka:9092
canal.mq.topic = system_operate_log_topic
canal.mq.partition = 0
canal.mq.retries = 3
canal.mq.acks = 1
canal.mq.maxMessageBytes = 1048576
canal.mq.batchSize = 100
canal.mq.timeout = 1000
```

## ClickHouse Kafka Engine 表 + MergeTree 表 + MV

### Kafka 表

```sql
CREATE TABLE kafka_system_operate_log (
    database String,
    table String,
    type String,
    ts UInt64,              -- ✅ 毫秒时间戳
    data String
)
ENGINE = Kafka
SETTINGS
    kafka_broker_list = 'kafka:9092',
    kafka_topic_list = 'system_operate_log_topic',
    kafka_group_name = 'clickhouse_syslog',
    kafka_format = 'JSONEachRow',
    kafka_num_consumers = 1;
```

### MergeTree 表

```sql
CREATE TABLE system_operate_log_storage (
    database String,
    table String,
    type String,
    event_time DateTime('Asia/Shanghai'),  -- ✅ 明确中国时区
    raw_ts UInt64,
    data String
)
ENGINE = MergeTree
PARTITION BY toYYYYMM(event_time)
ORDER BY (table, event_time);
```

### Materialized View

```sql
CREATE MATERIALIZED VIEW mv_system_operate_log
TO system_operate_log_storage
AS
SELECT
    database,
    table,
    type,
    toDateTime(ts / 1000, 'Asia/Shanghai') AS event_time,  -- ✅ 核心
    ts AS raw_ts,
    data
FROM kafka_system_operate_log;
```

### 手动创建

```sh
kafka-topics.sh --create \
  --bootstrap-server localhost:9092 \
  --replication-factor 1 \
  --partitions 1 \
  --topic system_operate_log_topic
```

### 关闭表结构快照

修改 `canal.properties`

```properties
#文件位置(容器里面修改)
/home/admin/canal-server/conf
# 关闭表结构快照（关键！！）
canal.instance.tsdb.enable=false
#canal.serverMode = tcp改成canal.serverMode = kafka
canal.serverMode = kafka
#canal.destinations = example 改成 canal.destinations = syslog
canal.destinations = syslog
#kafka.bootstrap.servers = 127.0.0.1:9092 改成 kafka.bootstrap.servers = //kafka:9092
kafka.bootstrap.servers = //kafka:9092
```

